# Agent runtime mode - llm_only | vlm_only | hybrid
AGENT_BRAIN_MODE=llm_only

# Enable/disable endpoints
LLM_ENABLED=1
VLM_ENABLED=0

# Shared key fallback (used if specific key is not set)
OPENAI_API_KEY=local

###################################################
# Survey target/version
# SURVEY_TARGET=http://localhost:3000/survey
# SURVEY_VERSION=survey_v0
SURVEY_TARGET=http://localhost:3000/survey_v1
SURVEY_VERSION=survey_v1

###################################################
# LLM models:
###################################################

# LLM_MODEL=meta-llama-3-8b-instruct
# MODEL_NAME=meta-llama-3-8b-instruct

# LLM_MODEL=mistral-7b-instruct-v0.3
# MODEL_NAME=mistral-7b-instruct-v0.3

# LLM_MODEL=qwen2.5-7b-instruct-1m
# MODEL_NAME=qwen2.5-7b-instruct-1m

# LLM endpoint
LLM_BASE_URL=http://127.0.0.1:1234/v1
LLM_API_KEY=local
LLM_TEMPERATURE=0.5
LLM_TIMEOUT_S=90

###################################################
# VLM models:
###################################################

# VLM_MODEL=qwen2.5-vl-7b-instruct
# MODEL_NAME=qwen2.5-vl-7b-instruct

# VLM_MODEL=llava-1.6-mistral-7b
# MODEL_NAME=llava-1.6-mistral-7b

# VLM_MODEL=minicpm-v-2_6
# MODEL_NAME=minicpm-v-2_6

# VLM endpoint
VLM_BASE_URL=http://127.0.0.1:1234/v1
VLM_API_KEY=local
VLM_TEMPERATURE=0.5
VLM_TIMEOUT_S=90
